{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["HiEPL1tEnMyH"],"mount_file_id":"1-5D_I55niMMfOHY0eGN-ZQZnVixtrKmf","authorship_tag":"ABX9TyPshu/8eZGi8fG/2bbyMsO3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fftk6LkbttGq","executionInfo":{"status":"ok","timestamp":1665519121812,"user_tz":-330,"elapsed":15456,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"0a28640a-c925-47eb-d4af-c03b85ad3176"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting streamlit\n","  Downloading streamlit-1.13.0-py2.py3-none-any.whl (9.2 MB)\n","\u001b[K     |████████████████████████████████| 9.2 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n","Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.0)\n","Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.3)\n","Collecting watchdog\n","  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (6.0.1)\n","Collecting pydeck>=0.1.dev5\n","  Downloading pydeck-0.8.0b3-py2.py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 44.5 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Collecting blinker>=1.0.0\n","  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.0.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.21.6)\n","Collecting rich>=10.11.0\n","  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n","\u001b[K     |████████████████████████████████| 237 kB 44.0 MB/s \n","\u001b[?25hCollecting pympler>=0.9\n","  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n","\u001b[K     |████████████████████████████████| 164 kB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.3.5)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n","Collecting validators>=0.2\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","Requirement already satisfied: protobuf!=3.20.2,<4,>=3.12 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n","Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n","Collecting gitpython!=3.1.19\n","  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 50.9 MB/s \n","\u001b[?25hCollecting semver\n","  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.12.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (4.3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->streamlit) (3.8.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (5.9.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (22.1.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.1->streamlit) (3.0.9)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2022.4)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.20.2,<4,>=3.12->streamlit) (1.15.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit) (2.10)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.11.0->streamlit) (2.6.1)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators>=0.2->streamlit) (4.4.2)\n","Building wheels for collected packages: validators\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=df86289caa6f4b7f2c21a729506e6a512bbe8652d7989ef2f7abdda18ac32dfd\n","  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n","Successfully built validators\n","Installing collected packages: smmap, gitdb, commonmark, watchdog, validators, semver, rich, pympler, pydeck, gitpython, blinker, streamlit\n","Successfully installed blinker-1.5 commonmark-0.9.1 gitdb-4.0.9 gitpython-3.1.29 pydeck-0.8.0b3 pympler-1.0.1 rich-12.6.0 semver-2.13.0 smmap-5.0.0 streamlit-1.13.0 validators-0.20.0 watchdog-2.1.9\n"]}]},{"cell_type":"code","source":["'''def main():\n","\tst.title(\"Covid19 Tweets Dashboard\")\n","\tst.subheader(\"Tweets Analysis\")\n","\tmenu = [\"Home\",\"About\"]\n","\tchoice = st.sidebar.selectbox('Menu',menu)\n","\tif choice == 'Home':\n","\t\tst.subheader(\"Covid19 Tweets Dashboard\")\t\n","\n","if __name__ == '__main__':\n","\tmain()'''"],"metadata":{"id":"F3bBnYz85zLC","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1665204362001,"user_tz":-330,"elapsed":498,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"a7056ffb-33ee-41e1-c3fc-4ce098894f73"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def main():\\n\\tst.title(\"Covid19 Tweets Dashboard\")\\n\\tst.subheader(\"Tweets Analysis\")\\n\\tmenu = [\"Home\",\"About\"]\\n\\tchoice = st.sidebar.selectbox(\\'Menu\\',menu)\\n\\tif choice == \\'Home\\':\\n\\t\\tst.subheader(\"Covid19 Tweets Dashboard\")\\t\\n\\nif __name__ == \\'__main__\\':\\n\\tmain()'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["!pip install snscrape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDVP4KLQeUSG","executionInfo":{"status":"ok","timestamp":1665519126788,"user_tz":-330,"elapsed":4981,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"9fb0b19a-646d-41cb-e977-df9c8475f3c3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting snscrape\n","  Downloading snscrape-0.3.4-py3-none-any.whl (35 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.9.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n","Installing collected packages: snscrape\n","Successfully installed snscrape-0.3.4\n"]}]},{"cell_type":"code","source":["!pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E47070DGeyFy","executionInfo":{"status":"ok","timestamp":1665519134907,"user_tz":-330,"elapsed":5763,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"7c27054a-329b-4464-979e-3afd6e5897e7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting emoji\n","  Downloading emoji-2.1.0.tar.gz (216 kB)\n","\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 40 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 216 kB 5.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-2.1.0-py3-none-any.whl size=212392 sha256=67fe11ff22bb9916f287aa56fdfc12bc18214721aace993848c9ad4f4e5d279f\n","  Stored in directory: /root/.cache/pip/wheels/77/75/99/51c2a119f4cfd3af7b49cc57e4f737bed7e40b348a85d82804\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-2.1.0\n"]}]},{"cell_type":"code","source":["!pip install plotly-express"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0mvamWXo6LA","executionInfo":{"status":"ok","timestamp":1665519138556,"user_tz":-330,"elapsed":3657,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"3333d6bf-862d-4151-c331-c5d4e0b470fc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting plotly-express\n","  Downloading plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from plotly-express) (1.21.6)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotly-express) (0.12.2)\n","Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from plotly-express) (5.5.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from plotly-express) (0.5.2)\n","Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from plotly-express) (1.7.3)\n","Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from plotly-express) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->plotly-express) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->plotly-express) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->plotly-express) (1.15.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.1.0->plotly-express) (8.1.0)\n","Installing collected packages: plotly-express\n","Successfully installed plotly-express-0.4.1\n"]}]},{"cell_type":"code","source":["!npm install localtunnel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xvoIietU6lC9","executionInfo":{"status":"ok","timestamp":1665519142717,"user_tz":-330,"elapsed":4167,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"e41adcd9-26e2-4c58-cba7-2305bf174be0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n","\u001b[0m\n","+ localtunnel@2.0.2\n","added 22 packages from 22 contributors and audited 22 packages in 2.379s\n","\n","3 packages are looking for funding\n","  run `npm fund` for details\n","\n","found \u001b[92m0\u001b[0m vulnerabilities\n","\n","\u001b[K\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install streamlit-autorefresh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxM0UJSuyS-H","executionInfo":{"status":"ok","timestamp":1665520981177,"user_tz":-330,"elapsed":6967,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"ff80ab10-7ce4-407b-c93b-bdc7b1a87fc9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting streamlit-autorefresh\n","  Downloading streamlit_autorefresh-0.0.1-py3-none-any.whl (345 kB)\n","\u001b[K     |████████████████████████████████| 345 kB 4.5 MB/s \n","\u001b[?25hRequirement already satisfied: streamlit>=0.75 in /usr/local/lib/python3.7/dist-packages (from streamlit-autorefresh) (1.13.0)\n","Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (2.23.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (0.10.2)\n","Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (21.3)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (1.21.6)\n","Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (1.0.1)\n","Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (1.3.5)\n","Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (1.5)\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (4.2.4)\n","Requirement already satisfied: protobuf!=3.20.2,<4,>=3.12 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (3.17.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (2.8.2)\n","Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (0.20.0)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (5.1.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (7.1.2)\n","Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (2.1.9)\n","Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (4.1.1)\n","Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (0.8.0b3)\n","Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (1.5.1)\n","Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (6.0.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (12.6.0)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (5.0.0)\n","Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (2.13.0)\n","Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (3.1.29)\n","Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit>=0.75->streamlit-autorefresh) (4.2.0)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit>=0.75->streamlit-autorefresh) (4.3.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit>=0.75->streamlit-autorefresh) (0.12.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit>=0.75->streamlit-autorefresh) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit>=0.75->streamlit-autorefresh) (2.11.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit>=0.75->streamlit-autorefresh) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=0.75->streamlit-autorefresh) (5.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->streamlit>=0.75->streamlit-autorefresh) (3.8.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.75->streamlit-autorefresh) (5.9.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.75->streamlit-autorefresh) (22.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.75->streamlit-autorefresh) (0.18.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.1->streamlit>=0.75->streamlit-autorefresh) (3.0.9)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit>=0.75->streamlit-autorefresh) (2022.4)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.20.2,<4,>=3.12->streamlit>=0.75->streamlit-autorefresh) (1.15.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit>=0.75->streamlit-autorefresh) (2.0.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit>=0.75->streamlit-autorefresh) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit>=0.75->streamlit-autorefresh) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit>=0.75->streamlit-autorefresh) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.4->streamlit>=0.75->streamlit-autorefresh) (2022.9.24)\n","Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.11.0->streamlit>=0.75->streamlit-autorefresh) (0.9.1)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.11.0->streamlit>=0.75->streamlit-autorefresh) (2.6.1)\n","Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators>=0.2->streamlit>=0.75->streamlit-autorefresh) (4.4.2)\n","Installing collected packages: streamlit-autorefresh\n","Successfully installed streamlit-autorefresh-0.0.1\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import plotly.express as px\n","import pickle\n","import streamlit as st\n","from streamlit_autorefresh import st_autorefresh\n","import snscrape.modules.twitter as sntwitter\n","import pandas as pd\n","from datetime import datetime, timedelta\n","import emoji as ej\n","import re\n","import string\n","# NLTK imports\n","import nltk\n","nltk.download('punkt')\n","# Download stopwords\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import CountVectorizer \n","st.set_option('deprecation.showPyplotGlobalUse', False) \n","\n","st.set_page_config(page_title = \"Covid19 Tweets Dashboard\",\n","                   page_icon = \":bar_chart:\",\n","                   layout = \"wide\")\n","\n","st.title(\"Covid19 Tweets Dashboard\")\n","st.markdown(\"---\")\n","\n","st_autorefresh(interval= 1 * 60 * 1000, key=\"dataframerefresh\")\n","\n","def extract_tweets():\n","    n = st.number_input(\"Enter the number of tweets to be extracted for last 1 day:\", min_value=1, step=1)\n","    tweets_list1 = []\n","    since_date = int((datetime.now()+timedelta(days=-1)).timestamp())\n","    until_date = int((datetime.now()).timestamp())\n","    i=-1\n","    try:\n","      n = abs(int(n))\n","    except Exception as e:\n","      print(\"Enter a valid number\\n\",e)\n","      raise\n","    for i, tweet in enumerate(\n","        sntwitter.TwitterSearchScraper(\n","            query='(covid OR covid19 OR coronavirus) min_replies:1 lang:en -filter:links -filter:replies until_time:{0} since_time:{1}'.format(until_date,since_date)\n","        ).get_items()\n","    ):\n","        tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.username])\n","        if((i + 1)==n):\n","            break\n","    else:\n","        print(\"Only {0} tweets available for past 24 hours\".format(i+1))\n","    tweets_df1 = pd.DataFrame(\n","        tweets_list1, columns=[\"Datetime\", \"Tweet Id\", \"Text\", \"Username\"]\n","    )\n","    return tweets_df1\n","\n","df = extract_tweets()\n","\n","def emoji_to_text(text):\n","    if type(text) != float:\n","        return (ej.demojize(text)).replace(\":\", \" \").replace(\"_\",\" \")\n","    else:\n","        return text.replace(\":\", \" \").replace(\"_\",\" \")\n","\n","\n","def remove_usernames_links(tweet):\n","    tweet = re.sub('@[^\\s]+','',tweet)\n","    tweet = re.sub('http[^\\s]+','',tweet)\n","    tweet = re.sub('#','',tweet)\n","    #emoj = re.compile(\"[\"\n","        #u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","        #u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","        #u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","        #u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","        #u\"\\U00002500-\\U00002BEF\"  # chinese char\n","        #u\"\\U00002702-\\U000027B0\"\n","        #u\"\\U00002702-\\U000027B0\"\n","        #u\"\\U000024C2-\\U0001F251\"\n","        #u\"\\U0001f926-\\U0001f937\"\n","        #u\"\\U00010000-\\U0010ffff\"\n","        #u\"\\u2640-\\u2642\" \n","        #u\"\\u2600-\\u2B55\"\n","        #u\"\\u200d\"\n","        #u\"\\u23cf\"\n","        #u\"\\u23e9\"\n","        #u\"\\u231a\"\n","        #u\"\\ufe0f\"  # dingbats\n","        #u\"\\u3030\"\n","        #              \"]+\", re.UNICODE)\n","    #return re.sub(emoj, '', tweet)\n","    return tweet\n","\n","def remove_mult_spaces(text): # remove multiple spaces\n","  return re.sub(\"\\s\\s+\" , \" \", text)\n","\n","contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n","                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n","                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n","                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n","                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n","                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n","                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n","                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n","                     \"i'd\": \"i would\", \"i'd've\": \"i would have\",\"i'll\": \"i will\",\n","                     \"i'll've\": \"i will have\",\"i'm\": \"i am\",\"i've\": \"i have\", \"isn't\": \"is not\",\n","                     \"it'd\": \"it would\",\"it’s\":\"it is\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n","                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n","                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n","                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n","                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n","                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n","                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n","                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n","                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n","                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n","                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n","                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n","                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n","                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n","                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n","                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n","                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n","                     \"what'll've\": \"what will have\",\"what're\": \"what are\",\"what’s\":\"what is\" ,\"what've\": \"what have\",\n","                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n","                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n","                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n","                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n","                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n","                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n","                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n","                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n","                     \"you've\": \"you have\"}\n","\n","# Regular expression for finding contractions\n","contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n","\n","# Function for expanding contractions\n","def expand_contractions(text,contractions_dict=contractions_dict):\n","  def replace(match):\n","    return contractions_dict[match.group(0)]\n","  return contractions_re.sub(replace, text)\n","\n","def CleanFurther(Text):\n","  Text = re.sub(\" \\d+\", \" \", Text) # Numbers \n","  Text = re.sub(r'(?:^| )\\w(?:$| )', ' ', Text).strip() #Single letters \n","  Text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'’()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', Text)  # remove punctuations\n","  Text = re.sub('\\s+', ' ',Text) #Extra whitespaces\n","  return Text\n","\n","stop_words = set(stopwords.words('english'))\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","def data_processing(df):\n","  # drop duplicates\n","  new_df = df.drop_duplicates(subset=['Tweet Id'], keep='first')\n","  new_df['text'] = new_df.Text.str.lower()\n","  new_df = new_df.drop(columns='Text')\n","  new_df = new_df[(new_df.text.str.contains('covid'))|(new_df.text.str.contains('coronavirus'))] #to ensure tweets have a reference to covid and are not extrcaed due to just the username having reference to covid\n","  new_df = new_df.reset_index(drop=True)\n","  new_df['text_ett'] = new_df['text'].apply(emoji_to_text)\n","  new_df['pr_text'] = new_df.text_ett.apply(lambda x:remove_usernames_links(x)).values\n","  new_df['pr_text']=new_df['pr_text'].apply(lambda x:expand_contractions(x))\n","  new_df['pr_text']=new_df['pr_text'].apply(lambda x:CleanFurther(x))\n","  new_df['pr_text_swr'] = new_df['pr_text'].apply(lambda x: ' '.join([str(w).strip('.') for w in word_tokenize(x) if not w in stop_words if not w in string.punctuation if not w in ['``',\"''\"]]))\n","  new_df['pr_text_swr_lemma'] = new_df.pr_text_swr.apply(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in x.split()]))\n","  return new_df\n","\n","df= data_processing(df)\n","\n","#st.sidebar.header(\"Filter the time duration here:\")\n","#time = st.sidebar.multiselect(\n","#\t\"Select the timeframe:\",\n","#\toptions = [\"10 min\", \"30 min\", \"1 hour\", \"2 hours\", \"6 hours\", \"12 hours\", \"1 Day\", \"1 Week\", \"1 month\", \"3 months\"],\n","#\tdefault = \"6 hours\"\n","#)\n","\n","#df_selection = df.query()\n","\n","#cv = CountVectorizer(min_df=3, max_df=0.4, binary=False, ngram_range=(1,2), max_features=4000)\n","\n","cv= pickle.load(open('/content/drive/MyDrive/finalized_model_cv1_08.sav', 'rb'))\n","\n","loaded_model = pickle.load(open('/content/drive/MyDrive/finalized_model_mnb_08.sav', 'rb'))\n","df.pr_text_swr_lemma=cv.transform(df.pr_text_swr_lemma)\n","#result = loaded_model.predict(df.pr_text_swr_lemma)\n","df['Sentiment']=loaded_model.predict(df.pr_text_swr_lemma)\n","\n","df1 = df[['Datetime', 'Tweet Id',\t'Username',\t'text', 'pr_text_swr_lemma','Sentiment']].copy()\n","\n","replacement_mapping_dict = {\n","    0 : \"Negative\",\n","    1 : \"Neutral\",\n","    2 : \"Positive\"\n","}\n","\n","df1['Sentiment'] = df1['Sentiment'].replace(replacement_mapping_dict)\n","\n","st.header(\":globe_with_meridians: Extracted Tweets\")\n","st.dataframe(df1, use_container_width=True)\n","st.markdown(\"---\")\n","\n","st.header(\":bar_chart: Tweets Analysis\")\n","st.markdown(\"##\")\n","\n","sentiment_count = df1['Sentiment'].value_counts().rename_axis('Sentiment').reset_index(name='Count')\n","#df1.groupby(by=['Sentiment']).sum()\n","sentiment_plot = px.bar(\n","  sentiment_count,\n","  x = 'Count',\n","  y = 'Sentiment',\n","  orientation = \"h\",\n","  color_discrete_sequence=[\"#0083B8\"]*len(sentiment_count)\n",")\n","sentiment_plot.update_layout(\n","  plot_bgcolor=\"rgba(0,0,0,0)\"\n",")\n","\n","from wordcloud   import WordCloud, STOPWORDS\n","import matplotlib.pyplot as plt\n","\n","stop_words_wc = stop_words\n","for word in ['no','not','nor']:\n","  stop_words_wc.add(word)\n","\n","def wordcloud(string,color):\n","    wc = WordCloud(background_color=color, width=1200,height=650,mask=None,random_state=1,\n","                   max_font_size=200,stopwords=stop_words_wc,collocations=False,repeat = False).generate(string)\n","    fig=plt.figure(figsize=(20,8))\n","    plt.axis('off')\n","    plt.imshow(wc)\n","\n","source_string = \" \".join(df1['pr_text_swr_lemma'].astype('str'))\n","fig = wordcloud(source_string,'Black')\n","\n","\n","left_column, right_column = st.columns(2)\n","with left_column:\n","  st.subheader(\"Sentiment Counts of Extracted Tweets\")\n","  st.plotly_chart(sentiment_plot)\n","with right_column:\n","  st.subheader(\"Word Cloud\")\n","  st.pyplot(fig)\n","\n","left_column, right_column = st.columns(2)\n","with left_column:\n","  if st.checkbox('Positive Tweets'):\n","    source_string1 = \" \".join(df1[(df1.Sentiment=='Positive')]['pr_text_swr_lemma'].astype('str'))\n","    if source_string1 != \"\":\n","      fig1 = wordcloud(source_string1,'Black')\n","      st.subheader(\"Word cloud for Positive Tweets\")\n","      st.pyplot(fig1, use_container_width=True)\n","with right_column:\n","  if st.checkbox('Negative Tweets'):\n","    source_string2 = \" \".join(df1[(df1.Sentiment=='Negative')]['pr_text_swr_lemma'].astype('str'))\n","    if source_string2 != \"\":\n","      fig2 = wordcloud(source_string2,'Black')\n","      st.subheader(\"Word cloud for Negative Tweets\")\n","      st.pyplot(fig2, use_container_width=True, clear_figure=False)\n","\n","st.markdown(\"---\")\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import NMF\n","from sklearn.pipeline import make_pipeline\n","tfidf_vectorizer1 = TfidfVectorizer(stop_words=stop_words, ngram_range=(2,3))\n","\n","left_column, right_column = st.columns(2)\n","with left_column:\n","  st.subheader(\"Top 5 Topics using NMF Topic Modelling\")\n","  nmf = NMF(n_components=5)\n","  pipe = make_pipeline(tfidf_vectorizer1, nmf)\n","  pipe.fit(df1['text'])\n","  def print_top_words(model, feature_names, n_top_words):\n","      for topic_idx, topic in enumerate(model.components_):\n","          message = \"Topic #%d: \" % (topic_idx+1)\n","          message += \", \".join([feature_names[i]\n","                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n","          st.write(message)\n","      print()\n","  print_top_words(nmf, tfidf_vectorizer1.get_feature_names(), n_top_words=3)\n","\n","with right_column:\n","  st.subheader(\"Top 5 Topics using LDA Topic Modelling\")\n","  from sklearn.decomposition import LatentDirichletAllocation\n","  tfidf_vectorizer2 = TfidfVectorizer(stop_words=stop_words, ngram_range=(2,3))\n","  lda = LatentDirichletAllocation(n_components=5)\n","  pipe1 = make_pipeline(tfidf_vectorizer2, lda)\n","  pipe1.fit(df1['text'])\n","  def print_top_words(model, feature_names, n_top_words):\n","      for topic_idx, topic in enumerate(model.components_):\n","          message = \"Topic #%d: \" % (topic_idx+1)\n","          message += \", \".join([feature_names[i]\n","                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n","          st.write(message)\n","      print()\n","  print_top_words(lda, tfidf_vectorizer2.get_feature_names(), n_top_words=3)\n","\n","def get_top_n_words(corpus, n=None):\n","    vec = CountVectorizer(stop_words='english').fit(corpus)\n","    bag_of_words = vec.transform(corpus)\n","    sum_words = bag_of_words.sum(axis=0) \n","    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n","    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n","    return words_freq[:n]\n","\n","common_words = get_top_n_words(df1['pr_text_swr_lemma'], 15)\n","df2 = pd.DataFrame(common_words, columns = ['Unigram' , 'Count'])\n","\n","def get_top_n_bigram(corpus, n=None):\n","    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n","    bag_of_words = vec.transform(corpus)\n","    sum_words = bag_of_words.sum(axis=0) \n","    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n","    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n","    return words_freq[:n]\n","\n","common_words1 = get_top_n_bigram(df1['pr_text_swr_lemma'], 15)\n","df3 = pd.DataFrame(common_words1, columns = ['Bigram' , 'Count'])\n","\n","def get_top_n_trigram(corpus, n=None):\n","    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n","    bag_of_words = vec.transform(corpus)\n","    sum_words = bag_of_words.sum(axis=0) \n","    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n","    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n","    return words_freq[:n]\n","\n","common_words2 = get_top_n_trigram(df1['pr_text_swr_lemma'], 15)\n","df4 = pd.DataFrame(common_words2, columns = ['Trigram' , 'Count'])\n","\n","left_column, middle_column, right_column = st.columns(3)\n","with left_column:\n","  st.subheader(\"Unigram\")\n","  st.dataframe(df2, use_container_width=True)\n","with middle_column:\n","  st.subheader(\"Bigram\")\n","  st.dataframe(df3, use_container_width=True)\n","with right_column:\n","  st.subheader(\"Trigram\")\n","  st.dataframe(df4, use_container_width=True)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqfvwWnu0hgd","executionInfo":{"status":"ok","timestamp":1665521006402,"user_tz":-330,"elapsed":388,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"ea897ffc-b410-43f1-a457-2d14012e574f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["!streamlit run app.py &>/dev/null&"],"metadata":{"id":"nHCTTWld0wFP","executionInfo":{"status":"ok","timestamp":1665521013420,"user_tz":-330,"elapsed":405,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!npx localtunnel --port 8501"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mEJ2_tfN6sre","executionInfo":{"status":"ok","timestamp":1665521175562,"user_tz":-330,"elapsed":159947,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"bc6fb43d-5205-4f60-dc32-4af174291c67"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25hnpx: installed 22 in 2.896s\n","your url is: https://dull-teams-teach-34-132-126-143.loca.lt\n","^C\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SufgOt_z60eO","executionInfo":{"status":"ok","timestamp":1665313901605,"user_tz":-330,"elapsed":384,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ooe1Osa660b7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CqyFSAE460Zl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Ignore\n","\n","\n","\n"],"metadata":{"id":"HiEPL1tEnMyH"}},{"cell_type":"code","source":["!pip install snscrape"],"metadata":{"id":"2pbyoOA6ubwC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import snscrape.modules.twitter as sntwitter\n","import pandas as pd\n","from datetime import datetime, timedelta"],"metadata":{"id":"tEsDqeEiupq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_tweets(n=5):\n","    tweets_list1 = []\n","    since_date = int((datetime.now()+timedelta(days=-1)).timestamp())\n","    until_date = int((datetime.now()).timestamp())\n","    i=-1\n","    try:\n","      n = abs(int(n))\n","    except Exception as e:\n","      print(\"Enter a valid number\\n\",e)\n","      raise\n","    for i, tweet in enumerate(\n","        sntwitter.TwitterSearchScraper(\n","            query='(covid OR covid19 OR coronavirus) min_replies:1 lang:en -filter:links -filter:replies until_time:{0} since_time:{1}'.format(until_date,since_date)\n","        ).get_items()\n","    ):\n","        tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.username])\n","        if((i + 1)==n):\n","            break\n","    else:\n","        print(\"Only {0} tweets available for past 24 hours\".format(i+1))\n","    tweets_df1 = pd.DataFrame(\n","        tweets_list1, columns=[\"Datetime\", \"Tweet Id\", \"Text\", \"Username\"]\n","    )\n","    return tweets_df1\n"],"metadata":{"id":"6GmwSMC0uu6x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df= extract_tweets(n=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZXxDEQA1u1sw","executionInfo":{"status":"ok","timestamp":1665069551048,"user_tz":-330,"elapsed":775,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"a7a60479-d50e-427a-fb3d-83bfbb5b11bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:snscrape.modules.twitter:Retrieving guest token from search page\n","2022-10-06 15:19:09.841 Retrieving guest token from search page\n","INFO:snscrape.base:Retrieving https://twitter.com/search?f=live&lang=en&q=%28covid+OR+covid19+OR+coronavirus%29+min_replies%3A1+lang%3Aen+-filter%3Alinks+-filter%3Areplies+until_time%3A1665069549+since_time%3A1664983149&src=spelling_expansion_revert_click\n","2022-10-06 15:19:09.858 Retrieving https://twitter.com/search?f=live&lang=en&q=%28covid+OR+covid19+OR+coronavirus%29+min_replies%3A1+lang%3Aen+-filter%3Alinks+-filter%3Areplies+until_time%3A1665069549+since_time%3A1664983149&src=spelling_expansion_revert_click\n","INFO:snscrape.modules.twitter:Retrieving scroll page None\n","2022-10-06 15:19:10.061 Retrieving scroll page None\n","INFO:snscrape.base:Retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_composer_source=true&include_ext_alt_text=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=%28covid+OR+covid19+OR+coronavirus%29+min_replies%3A1+lang%3Aen+-filter%3Alinks+-filter%3Areplies+until_time%3A1665069549+since_time%3A1664983149&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%252CcameraMoment\n","2022-10-06 15:19:10.071 Retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_composer_source=true&include_ext_alt_text=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=%28covid+OR+covid19+OR+coronavirus%29+min_replies%3A1+lang%3Aen+-filter%3Alinks+-filter%3Areplies+until_time%3A1665069549+since_time%3A1664983149&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&ext=mediaStats%252CcameraMoment\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"uhpU8LSmu3fe","executionInfo":{"status":"ok","timestamp":1665069552888,"user_tz":-330,"elapsed":4,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"49bba27c-bd3d-48ae-8122-3df2a68e9b26"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   Datetime             Tweet Id  \\\n","0 2022-10-06 15:18:06+00:00  1578041919019663361   \n","1 2022-10-06 15:17:19+00:00  1578041718741540865   \n","2 2022-10-06 15:16:08+00:00  1578041423634599936   \n","3 2022-10-06 15:15:29+00:00  1578041259112931330   \n","4 2022-10-06 15:15:15+00:00  1578041199054802946   \n","\n","                                                Text        Username  \n","0  Poll: I got my covid booster and flu shot this...    EmmaSManning  \n","1  Wow, what an incredible team of people to help...          DrSdeG  \n","2  Myth: #Omicron is the mildest variant yet.\\nTr...       Billius27  \n","3  How did people die before coronavirus was inve...       EzraKahan  \n","4  Cw- death, covid\\n\\nFirst of I want to thank y...  And_Pixie_Dust  "],"text/html":["\n","  <div id=\"df-bfa3c580-9fd6-4001-864c-28b73a372f0e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datetime</th>\n","      <th>Tweet Id</th>\n","      <th>Text</th>\n","      <th>Username</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-10-06 15:18:06+00:00</td>\n","      <td>1578041919019663361</td>\n","      <td>Poll: I got my covid booster and flu shot this...</td>\n","      <td>EmmaSManning</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-10-06 15:17:19+00:00</td>\n","      <td>1578041718741540865</td>\n","      <td>Wow, what an incredible team of people to help...</td>\n","      <td>DrSdeG</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-10-06 15:16:08+00:00</td>\n","      <td>1578041423634599936</td>\n","      <td>Myth: #Omicron is the mildest variant yet.\\nTr...</td>\n","      <td>Billius27</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-10-06 15:15:29+00:00</td>\n","      <td>1578041259112931330</td>\n","      <td>How did people die before coronavirus was inve...</td>\n","      <td>EzraKahan</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-10-06 15:15:15+00:00</td>\n","      <td>1578041199054802946</td>\n","      <td>Cw- death, covid\\n\\nFirst of I want to thank y...</td>\n","      <td>And_Pixie_Dust</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfa3c580-9fd6-4001-864c-28b73a372f0e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bfa3c580-9fd6-4001-864c-28b73a372f0e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bfa3c580-9fd6-4001-864c-28b73a372f0e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["!pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0k45gVMlvVgP","executionInfo":{"status":"ok","timestamp":1665069566959,"user_tz":-330,"elapsed":5968,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"56591cf9-eb35-43e6-f539-b2fa87768023"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (2.1.0)\n"]}]},{"cell_type":"code","source":["import emoji as ej\n","import re\n","import string\n","# NLTK imports\n","import nltk\n","nltk.download('punkt')\n","# Download stopwords\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer"],"metadata":{"id":"iIer9P4EvJgf","executionInfo":{"status":"ok","timestamp":1665069577751,"user_tz":-330,"elapsed":4,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f823a0f-37f8-45e3-f0ba-9c23b95fb2df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"code","source":["def emoji_to_text(text):\n","    if type(text) != float:\n","        return (ej.demojize(text)).replace(\":\", \" \").replace(\"_\",\" \")\n","    else:\n","        return text.replace(\":\", \" \").replace(\"_\",\" \")\n","\n","\n","def remove_usernames_links(tweet):\n","    tweet = re.sub('@[^\\s]+','',tweet)\n","    tweet = re.sub('http[^\\s]+','',tweet)\n","    tweet = re.sub('#','',tweet)\n","    #emoj = re.compile(\"[\"\n","        #u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","        #u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","        #u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","        #u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","        #u\"\\U00002500-\\U00002BEF\"  # chinese char\n","        #u\"\\U00002702-\\U000027B0\"\n","        #u\"\\U00002702-\\U000027B0\"\n","        #u\"\\U000024C2-\\U0001F251\"\n","        #u\"\\U0001f926-\\U0001f937\"\n","        #u\"\\U00010000-\\U0010ffff\"\n","        #u\"\\u2640-\\u2642\" \n","        #u\"\\u2600-\\u2B55\"\n","        #u\"\\u200d\"\n","        #u\"\\u23cf\"\n","        #u\"\\u23e9\"\n","        #u\"\\u231a\"\n","        #u\"\\ufe0f\"  # dingbats\n","        #u\"\\u3030\"\n","        #              \"]+\", re.UNICODE)\n","    #return re.sub(emoj, '', tweet)\n","    return tweet\n","\n","def remove_mult_spaces(text): # remove multiple spaces\n","  return re.sub(\"\\s\\s+\" , \" \", text)\n","\n","contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n","                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n","                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n","                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n","                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n","                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n","                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n","                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n","                     \"i'd\": \"i would\", \"i'd've\": \"i would have\",\"i'll\": \"i will\",\n","                     \"i'll've\": \"i will have\",\"i'm\": \"i am\",\"i've\": \"i have\", \"isn't\": \"is not\",\n","                     \"it'd\": \"it would\",\"it’s\":\"it is\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n","                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n","                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n","                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n","                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n","                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n","                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n","                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n","                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n","                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n","                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n","                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n","                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n","                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n","                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n","                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n","                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n","                     \"what'll've\": \"what will have\",\"what're\": \"what are\",\"what’s\":\"what is\" ,\"what've\": \"what have\",\n","                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n","                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n","                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n","                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n","                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n","                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n","                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n","                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n","                     \"you've\": \"you have\"}\n","\n","# Regular expression for finding contractions\n","contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n","\n","# Function for expanding contractions\n","def expand_contractions(text,contractions_dict=contractions_dict):\n","  def replace(match):\n","    return contractions_dict[match.group(0)]\n","  return contractions_re.sub(replace, text)\n","\n","def CleanFurther(Text):\n","  Text = re.sub(\" \\d+\", \" \", Text) # Numbers \n","  Text = re.sub(r'(?:^| )\\w(?:$| )', ' ', Text).strip() #Single letters \n","  Text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'’()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', Text)  # remove punctuations\n","  Text = re.sub('\\s+', ' ',Text) #Extra whitespaces\n","  return Text\n","\n","stop_words = set(stopwords.words('english'))\n","\n","lemmatizer = WordNetLemmatizer()"],"metadata":{"id":"LjmqNk0lvLwG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def data_processing(df):\n","  # drop duplicates\n","  new_df = df.drop_duplicates(subset=['Tweet Id'], keep='first')\n","  new_df['text'] = new_df.Text.str.lower()\n","  new_df = new_df.drop(columns='Text')\n","  new_df = new_df[(new_df.text.str.contains('covid'))|(new_df.text.str.contains('coronavirus'))] #to ensure tweets have a reference to covid and are not extrcaed due to just the username having reference to covid\n","  new_df = new_df.reset_index(drop=True)\n","  new_df['text_ett'] = new_df['text'].apply(emoji_to_text)\n","  new_df['pr_text'] = new_df.text_ett.apply(lambda x:remove_usernames_links(x)).values\n","  new_df['pr_text']=new_df['pr_text'].apply(lambda x:expand_contractions(x))\n","  new_df['pr_text']=new_df['pr_text'].apply(lambda x:CleanFurther(x))\n","  new_df['pr_text_swr'] = new_df['pr_text'].apply(lambda x: ' '.join([str(w).strip('.') for w in word_tokenize(x) if not w in stop_words if not w in string.punctuation if not w in ['``',\"''\"]]))\n","  new_df['pr_text_swr_lemma'] = new_df.pr_text_swr.apply(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in x.split()]))\n","  return new_df"],"metadata":{"id":"Cx4noNJsu5VX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df= data_processing(df)"],"metadata":{"id":"ELa05ftlu_BM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"id":"lDCsmRrYwS0f","executionInfo":{"status":"ok","timestamp":1665069595579,"user_tz":-330,"elapsed":532,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"36ec3bae-8849-4d58-ab5d-6192c759b6a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   Datetime             Tweet Id        Username  \\\n","0 2022-10-06 15:18:06+00:00  1578041919019663361    EmmaSManning   \n","1 2022-10-06 15:17:19+00:00  1578041718741540865          DrSdeG   \n","2 2022-10-06 15:16:08+00:00  1578041423634599936       Billius27   \n","3 2022-10-06 15:15:29+00:00  1578041259112931330       EzraKahan   \n","4 2022-10-06 15:15:15+00:00  1578041199054802946  And_Pixie_Dust   \n","\n","                                                text  \\\n","0  poll: i got my covid booster and flu shot this...   \n","1  wow, what an incredible team of people to help...   \n","2  myth: #omicron is the mildest variant yet.\\ntr...   \n","3  how did people die before coronavirus was inve...   \n","4  cw- death, covid\\n\\nfirst of i want to thank y...   \n","\n","                                            text_ett  \\\n","0  poll  i got my covid booster and flu shot this...   \n","1  wow, what an incredible team of people to help...   \n","2  myth  #omicron is the mildest variant yet.\\ntr...   \n","3  how did people die before coronavirus was inve...   \n","4  cw- death, covid\\n\\nfirst of i want to thank y...   \n","\n","                                             pr_text  \\\n","0  poll got my covid booster and flu shot this mo...   \n","1  wow what an incredible team of people to help ...   \n","2  myth omicron is the mildest variant yet truth ...   \n","3  how did people die before coronavirus was inve...   \n","4  cw death covid first of want to thank you all ...   \n","\n","                                         pr_text_swr  \\\n","0  poll got covid booster flu shot morning thus c...   \n","1  wow incredible team people help us evelina lon...   \n","2  myth omicron mildest variant yet truth omicron...   \n","3                    people die coronavirus invented   \n","4  cw death covid first want thank suggestions th...   \n","\n","                                   pr_text_swr_lemma  \n","0  poll got covid booster flu shot morning thus c...  \n","1  wow incredible team people help u evelina long...  \n","2  myth omicron mildest variant yet truth omicron...  \n","3                    people die coronavirus invented  \n","4  cw death covid first want thank suggestion thi...  "],"text/html":["\n","  <div id=\"df-1ee849f9-7ee3-4fc4-acf6-4c31601916d0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datetime</th>\n","      <th>Tweet Id</th>\n","      <th>Username</th>\n","      <th>text</th>\n","      <th>text_ett</th>\n","      <th>pr_text</th>\n","      <th>pr_text_swr</th>\n","      <th>pr_text_swr_lemma</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-10-06 15:18:06+00:00</td>\n","      <td>1578041919019663361</td>\n","      <td>EmmaSManning</td>\n","      <td>poll: i got my covid booster and flu shot this...</td>\n","      <td>poll  i got my covid booster and flu shot this...</td>\n","      <td>poll got my covid booster and flu shot this mo...</td>\n","      <td>poll got covid booster flu shot morning thus c...</td>\n","      <td>poll got covid booster flu shot morning thus c...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-10-06 15:17:19+00:00</td>\n","      <td>1578041718741540865</td>\n","      <td>DrSdeG</td>\n","      <td>wow, what an incredible team of people to help...</td>\n","      <td>wow, what an incredible team of people to help...</td>\n","      <td>wow what an incredible team of people to help ...</td>\n","      <td>wow incredible team people help us evelina lon...</td>\n","      <td>wow incredible team people help u evelina long...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-10-06 15:16:08+00:00</td>\n","      <td>1578041423634599936</td>\n","      <td>Billius27</td>\n","      <td>myth: #omicron is the mildest variant yet.\\ntr...</td>\n","      <td>myth  #omicron is the mildest variant yet.\\ntr...</td>\n","      <td>myth omicron is the mildest variant yet truth ...</td>\n","      <td>myth omicron mildest variant yet truth omicron...</td>\n","      <td>myth omicron mildest variant yet truth omicron...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-10-06 15:15:29+00:00</td>\n","      <td>1578041259112931330</td>\n","      <td>EzraKahan</td>\n","      <td>how did people die before coronavirus was inve...</td>\n","      <td>how did people die before coronavirus was inve...</td>\n","      <td>how did people die before coronavirus was inve...</td>\n","      <td>people die coronavirus invented</td>\n","      <td>people die coronavirus invented</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-10-06 15:15:15+00:00</td>\n","      <td>1578041199054802946</td>\n","      <td>And_Pixie_Dust</td>\n","      <td>cw- death, covid\\n\\nfirst of i want to thank y...</td>\n","      <td>cw- death, covid\\n\\nfirst of i want to thank y...</td>\n","      <td>cw death covid first of want to thank you all ...</td>\n","      <td>cw death covid first want thank suggestions th...</td>\n","      <td>cw death covid first want thank suggestion thi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ee849f9-7ee3-4fc4-acf6-4c31601916d0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1ee849f9-7ee3-4fc4-acf6-4c31601916d0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1ee849f9-7ee3-4fc4-acf6-4c31601916d0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["st.dataframe(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fZRU_aDuXIi","executionInfo":{"status":"ok","timestamp":1665069601125,"user_tz":-330,"elapsed":433,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"1a0d7141-6f31-4bbb-b531-e7873302eb0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeltaGenerator(_root_container=0, _provided_cursor=None, _parent=None, _block_type=None, _form_data=None)"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["#!./ngrok authtokens 2FlYOMV8kjXbMWW6yrOvW4Vg0bX_5Dq97DVKWnyi5Ds3eU4cX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YJoNVbLwwab","executionInfo":{"status":"ok","timestamp":1665068369095,"user_tz":-330,"elapsed":710,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"0592ef28-8723-4bbf-f4d5-a1dc91756f79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: ./ngrok: No such file or directory\n"]}]},{"cell_type":"code","source":["#!npm install localtunnel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJYOVk8m1tme","executionInfo":{"status":"ok","timestamp":1665068891292,"user_tz":-330,"elapsed":4345,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"35477975-67c6-412c-832b-6ca2dbca75a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n","\u001b[0m\n","+ localtunnel@2.0.2\n","added 22 packages from 22 contributors and audited 22 packages in 2.682s\n","\n","3 packages are looking for funding\n","  run `npm fund` for details\n","\n","found \u001b[92m0\u001b[0m vulnerabilities\n","\n","\u001b[K\u001b[?25h"]}]},{"cell_type":"code","source":["#!npx localtunnel --port 8501"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Npg-CRty10U-","executionInfo":{"status":"ok","timestamp":1665069147242,"user_tz":-330,"elapsed":215849,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"0874658e-e45e-4bb5-a8a9-14ff9a4f0ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25hnpx: installed 22 in 1.739s\n","your url is: https://sixty-emus-win-35-188-231-115.loca.lt\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:pyngrok.process.ngrok:t=2022-10-06T15:11:28+0000 lvl=warn msg=\"failed to open private leg\" id=2c8a390d9026 privaddr=localhost:80 err=\"dial tcp 127.0.0.1:80: connect: connection refused\"\n","2022-10-06 15:11:28.352 t=2022-10-06T15:11:28+0000 lvl=warn msg=\"failed to open private leg\" id=2c8a390d9026 privaddr=localhost:80 err=\"dial tcp 127.0.0.1:80: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2022-10-06T15:11:28+0000 lvl=warn msg=\"failed to open private leg\" id=166c8c44a65a privaddr=localhost:80 err=\"dial tcp 127.0.0.1:80: connect: connection refused\"\n","2022-10-06 15:11:28.668 t=2022-10-06T15:11:28+0000 lvl=warn msg=\"failed to open private leg\" id=166c8c44a65a privaddr=localhost:80 err=\"dial tcp 127.0.0.1:80: connect: connection refused\"\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:12:26+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n","2022-10-06 15:12:26.553 t=2022-10-06T15:12:26+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n"]},{"output_type":"stream","name":"stdout","text":["^C\n"]}]},{"cell_type":"code","source":["!streamlit run app.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m78Z1b6K4iNo","executionInfo":{"status":"ok","timestamp":1665069817955,"user_tz":-330,"elapsed":59913,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"7048ddf7-183e-486d-bf67-c8d9486e67dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-10-06 15:22:38.540 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n","\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.188.231.115:8501\u001b[0m\n","\u001b[0m\n","\u001b[34m  Stopping...\u001b[0m\n","^C\n"]}]},{"cell_type":"code","source":["pip install pyngrok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJyeDvv0zqyX","executionInfo":{"status":"ok","timestamp":1665068358797,"user_tz":-330,"elapsed":6747,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"47f3ada7-aac2-4449-e2f5-13864207f9b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyngrok\n","  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n","\u001b[K     |████████████████████████████████| 745 kB 25.5 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=5dc2eb86b0ea4e8da7acb7595ec9a4a2d0bc752f614e03941b926c6b10a0a49c\n","  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-5.1.0\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57ArhXxR0MeI","executionInfo":{"status":"ok","timestamp":1665068493182,"user_tz":-330,"elapsed":552,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"96c4515a-f0c4-4549-e2ec-4006bd2120db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\n"]}]},{"cell_type":"code","source":["from pyngrok import ngrok\n","\n","public_url = ngrok.connect(port='8501')\n","public_url"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bm1Wz8830ONo","executionInfo":{"status":"ok","timestamp":1665068707859,"user_tz":-330,"elapsed":773,"user":{"displayName":"capstone group12cds","userId":"05661648728044947725"}},"outputId":"5667e2a8-b19d-4c64-efaa-9df0be875385"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pyngrok.ngrok:Opening tunnel named: http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9\n","2022-10-06 15:05:06.519 Opening tunnel named: http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9\n"]},{"output_type":"stream","name":"stdout","text":[]},{"output_type":"stream","name":"stderr","text":["INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=\"no configuration paths supplied\"\n","2022-10-06 15:05:07.331 t=2022-10-06T15:05:07+0000 lvl=info msg=\"no configuration paths supplied\"\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.ngrok2/ngrok.yml\n","2022-10-06 15:05:07.361 t=2022-10-06T15:05:07+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.ngrok2/ngrok.yml\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=\"open config file\" path=/root/.ngrok2/ngrok.yml err=nil\n","2022-10-06 15:05:07.374 t=2022-10-06T15:05:07+0000 lvl=info msg=\"open config file\" path=/root/.ngrok2/ngrok.yml err=nil\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040\n","2022-10-06 15:05:07.381 t=2022-10-06T15:05:07+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n","2022-10-06 15:05:07.444 t=2022-10-06T15:05:07+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=\"client session established\" obj=csess id=85901e66c070\n","2022-10-06 15:05:07.454 t=2022-10-06T15:05:07+0000 lvl=info msg=\"client session established\" obj=csess id=85901e66c070\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=start pg=/api/tunnels id=7320620b0b750b7b\n","2022-10-06 15:05:07.466 t=2022-10-06T15:05:07+0000 lvl=info msg=start pg=/api/tunnels id=7320620b0b750b7b\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=end pg=/api/tunnels id=7320620b0b750b7b status=200 dur=470.785µs\n","2022-10-06 15:05:07.482 t=2022-10-06T15:05:07+0000 lvl=info msg=end pg=/api/tunnels id=7320620b0b750b7b status=200 dur=470.785µs\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=start pg=/api/tunnels id=4cf0b0e871852fd8\n","2022-10-06 15:05:07.490 t=2022-10-06T15:05:07+0000 lvl=info msg=start pg=/api/tunnels id=4cf0b0e871852fd8\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=end pg=/api/tunnels id=4cf0b0e871852fd8 status=200 dur=160.102µs\n","2022-10-06 15:05:07.499 t=2022-10-06T15:05:07+0000 lvl=info msg=end pg=/api/tunnels id=4cf0b0e871852fd8 status=200 dur=160.102µs\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=start pg=/api/tunnels id=4f3b6b84c292ff49\n","2022-10-06 15:05:07.507 t=2022-10-06T15:05:07+0000 lvl=info msg=start pg=/api/tunnels id=4f3b6b84c292ff49\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=\"http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9 (http)\" addr=http://localhost:80 url=http://2f81-35-188-231-115.ngrok.io\n"]},{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"http://2f81-35-188-231-115.ngrok.io\" -> \"http://localhost:80\">"]},"metadata":{},"execution_count":30},{"output_type":"stream","name":"stderr","text":["2022-10-06 15:05:07.535 t=2022-10-06T15:05:07+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=\"http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9 (http)\" addr=http://localhost:80 url=http://2f81-35-188-231-115.ngrok.io\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9 addr=http://localhost:80 url=https://2f81-35-188-231-115.ngrok.io\n","2022-10-06 15:05:07.551 t=2022-10-06T15:05:07+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9 addr=http://localhost:80 url=https://2f81-35-188-231-115.ngrok.io\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=end pg=/api/tunnels id=4f3b6b84c292ff49 status=201 dur=39.296986ms\n","2022-10-06 15:05:07.562 t=2022-10-06T15:05:07+0000 lvl=info msg=end pg=/api/tunnels id=4f3b6b84c292ff49 status=201 dur=39.296986ms\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=start pg=\"/api/tunnels/http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9 (http)\" id=eb3871cf5935282a\n","2022-10-06 15:05:07.572 t=2022-10-06T15:05:07+0000 lvl=info msg=start pg=\"/api/tunnels/http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9 (http)\" id=eb3871cf5935282a\n","INFO:pyngrok.process.ngrok:t=2022-10-06T15:05:07+0000 lvl=info msg=end pg=\"/api/tunnels/http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9 (http)\" id=eb3871cf5935282a status=200 dur=246.423µs\n","2022-10-06 15:05:07.595 t=2022-10-06T15:05:07+0000 lvl=info msg=end pg=\"/api/tunnels/http-80-b89ae37e-3c63-4e58-b424-5a50abcd09d9 (http)\" id=eb3871cf5935282a status=200 dur=246.423µs\n"]}]}]}